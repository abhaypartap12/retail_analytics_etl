[2025-07-02T15:19:50.161+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: retail_sales_pipeline.run_spark_job manual__2025-07-02T15:14:39.584681+00:00 [queued]>
[2025-07-02T15:19:50.194+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: retail_sales_pipeline.run_spark_job manual__2025-07-02T15:14:39.584681+00:00 [queued]>
[2025-07-02T15:19:50.194+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-02T15:19:50.195+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-02T15:19:50.196+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-02T15:19:50.289+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): run_spark_job> on 2025-07-02 15:14:39.584681+00:00
[2025-07-02T15:19:50.342+0000] {standard_task_runner.py:55} INFO - Started process 463 to run task
[2025-07-02T15:19:50.352+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'retail_sales_pipeline', 'run_spark_job', 'manual__2025-07-02T15:14:39.584681+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/retail_sales_pipeline.py', '--cfg-path', '/tmp/tmp1652i5lh']
[2025-07-02T15:19:50.356+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask run_spark_job
[2025-07-02T15:19:51.038+0000] {task_command.py:389} INFO - Running <TaskInstance: retail_sales_pipeline.run_spark_job manual__2025-07-02T15:14:39.584681+00:00 [running]> on host febdae18cce2
[2025-07-02T15:19:51.630+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=retail_sales_pipeline
AIRFLOW_CTX_TASK_ID=run_spark_job
AIRFLOW_CTX_EXECUTION_DATE=2025-07-02T15:14:39.584681+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-07-02T15:14:39.584681+00:00
[2025-07-02T15:19:51.641+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-02T15:19:51.651+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', '\n        docker exec spark-master /opt/bitnami/spark/bin/spark-submit             --master spark://spark-master:7077             --jars /opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.5.5.jar,/opt/bitnami/spark/jars/kafka-clients-3.5.1.jar,/opt/bitnami/spark/jars/kafka_2.12-3.5.1.jar,/opt/bitnami/spark/jars/commons-pool2-2.11.1.jar,/opt/bitnami/spark/jars/delta-spark_2.12-3.0.0.jar,/opt/bitnami/spark/jars/delta-storage-3.0.0.jar,/opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.5.jar             /opt/***/scripts/transformation/process_sales_new.py\n        ']
[2025-07-02T15:19:51.742+0000] {subprocess.py:86} INFO - Output:
[2025-07-02T15:20:02.262+0000] {subprocess.py:93} INFO - 25/07/02 15:20:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-02T15:20:06.446+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO SparkContext: Running Spark version 3.5.5
[2025-07-02T15:20:06.455+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, amd64
[2025-07-02T15:20:06.457+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO SparkContext: Java version 17.0.14
[2025-07-02T15:20:06.655+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceUtils: ==============================================================
[2025-07-02T15:20:06.663+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-02T15:20:06.665+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceUtils: ==============================================================
[2025-07-02T15:20:06.671+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO SparkContext: Submitted application: KafkaToCSVBatchJob
[2025-07-02T15:20:06.873+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-02T15:20:06.917+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceProfile: Limiting resource is cpu
[2025-07-02T15:20:06.942+0000] {subprocess.py:93} INFO - 25/07/02 15:20:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-02T15:20:07.209+0000] {subprocess.py:93} INFO - 25/07/02 15:20:07 INFO SecurityManager: Changing view acls to: spark
[2025-07-02T15:20:07.212+0000] {subprocess.py:93} INFO - 25/07/02 15:20:07 INFO SecurityManager: Changing modify acls to: spark
[2025-07-02T15:20:07.214+0000] {subprocess.py:93} INFO - 25/07/02 15:20:07 INFO SecurityManager: Changing view acls groups to:
[2025-07-02T15:20:07.223+0000] {subprocess.py:93} INFO - 25/07/02 15:20:07 INFO SecurityManager: Changing modify acls groups to:
[2025-07-02T15:20:07.227+0000] {subprocess.py:93} INFO - 25/07/02 15:20:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
[2025-07-02T15:20:08.707+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO Utils: Successfully started service 'sparkDriver' on port 44055.
[2025-07-02T15:20:08.795+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO SparkEnv: Registering MapOutputTracker
[2025-07-02T15:20:08.931+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-02T15:20:08.977+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-02T15:20:08.980+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-02T15:20:08.992+0000] {subprocess.py:93} INFO - 25/07/02 15:20:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-02T15:20:09.044+0000] {subprocess.py:93} INFO - 25/07/02 15:20:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-138120f0-266f-43a8-9659-cc9405b89a5d
[2025-07-02T15:20:09.080+0000] {subprocess.py:93} INFO - 25/07/02 15:20:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-02T15:20:09.108+0000] {subprocess.py:93} INFO - 25/07/02 15:20:09 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-02T15:20:09.761+0000] {subprocess.py:93} INFO - 25/07/02 15:20:09 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-02T15:20:10.099+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-07-02T15:20:10.476+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.5.5.jar at spark://ddb9a68c03a1:44055/jars/spark-sql-kafka-0-10_2.12-3.5.5.jar with timestamp 1751469606379
[2025-07-02T15:20:10.479+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/kafka-clients-3.5.1.jar at spark://ddb9a68c03a1:44055/jars/kafka-clients-3.5.1.jar with timestamp 1751469606379
[2025-07-02T15:20:10.480+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/kafka_2.12-3.5.1.jar at spark://ddb9a68c03a1:44055/jars/kafka_2.12-3.5.1.jar with timestamp 1751469606379
[2025-07-02T15:20:10.481+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/commons-pool2-2.11.1.jar at spark://ddb9a68c03a1:44055/jars/commons-pool2-2.11.1.jar with timestamp 1751469606379
[2025-07-02T15:20:10.483+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/delta-spark_2.12-3.0.0.jar at spark://ddb9a68c03a1:44055/jars/delta-spark_2.12-3.0.0.jar with timestamp 1751469606379
[2025-07-02T15:20:10.484+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/delta-storage-3.0.0.jar at spark://ddb9a68c03a1:44055/jars/delta-storage-3.0.0.jar with timestamp 1751469606379
[2025-07-02T15:20:10.487+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.5.jar at spark://ddb9a68c03a1:44055/jars/spark-token-provider-kafka-0-10_2.12-3.5.5.jar with timestamp 1751469606379
[2025-07-02T15:20:10.915+0000] {subprocess.py:93} INFO - 25/07/02 15:20:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-07-02T15:20:11.136+0000] {subprocess.py:93} INFO - 25/07/02 15:20:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.9:7077 after 86 ms (0 ms spent in bootstraps)
[2025-07-02T15:20:12.561+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250702152012-0000
[2025-07-02T15:20:12.716+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45547.
[2025-07-02T15:20:12.718+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO NettyBlockTransferService: Server created on ddb9a68c03a1:45547
[2025-07-02T15:20:12.740+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-02T15:20:12.839+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ddb9a68c03a1, 45547, None)
[2025-07-02T15:20:12.893+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250702152012-0000/0 on worker-20250702150121-172.18.0.10-34685 (172.18.0.10:34685) with 8 core(s)
[2025-07-02T15:20:12.895+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO BlockManagerMasterEndpoint: Registering block manager ddb9a68c03a1:45547 with 434.4 MiB RAM, BlockManagerId(driver, ddb9a68c03a1, 45547, None)
[2025-07-02T15:20:12.920+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ddb9a68c03a1, 45547, None)
[2025-07-02T15:20:12.956+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ddb9a68c03a1, 45547, None)
[2025-07-02T15:20:12.978+0000] {subprocess.py:93} INFO - 25/07/02 15:20:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20250702152012-0000/0 on hostPort 172.18.0.10:34685 with 8 core(s), 1024.0 MiB RAM
[2025-07-02T15:20:14.129+0000] {subprocess.py:93} INFO - 25/07/02 15:20:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-07-02T15:20:16.024+0000] {subprocess.py:93} INFO - 25/07/02 15:20:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250702152012-0000/0 is now RUNNING
[2025-07-02T15:20:16.654+0000] {subprocess.py:93} INFO - 25/07/02 15:20:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-02T15:20:16.686+0000] {subprocess.py:93} INFO - 25/07/02 15:20:16 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
[2025-07-02T15:20:27.009+0000] {subprocess.py:93} INFO - 25/07/02 15:20:26 INFO CodeGenerator: Code generated in 2127.685292 ms
[2025-07-02T15:20:27.373+0000] {subprocess.py:93} INFO - 25/07/02 15:20:27 INFO CodeGenerator: Code generated in 229.630208 ms
[2025-07-02T15:20:33.924+0000] {subprocess.py:93} INFO - 25/07/02 15:20:33 INFO InMemoryFileIndex: It took 542 ms to list leaf files for 1 paths.
[2025-07-02T15:20:36.897+0000] {subprocess.py:93} INFO - 25/07/02 15:20:36 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.10:45878) with ID 0,  ResourceProfileId 0
[2025-07-02T15:20:37.955+0000] {subprocess.py:93} INFO - 25/07/02 15:20:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.10:38649 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.10, 38649, None)
[2025-07-02T15:20:38.017+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO SparkContext: Starting job: parquet at <unknown>:0
[2025-07-02T15:20:38.163+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO DAGScheduler: Got job 0 (parquet at <unknown>:0) with 1 output partitions
[2025-07-02T15:20:38.165+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at <unknown>:0)
[2025-07-02T15:20:38.167+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:20:38.171+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:20:38.194+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at <unknown>:0), which has no missing parents
[2025-07-02T15:20:38.863+0000] {subprocess.py:93} INFO - 25/07/02 15:20:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 104.7 KiB, free 434.3 MiB)
[2025-07-02T15:20:39.078+0000] {subprocess.py:93} INFO - 25/07/02 15:20:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 434.3 MiB)
[2025-07-02T15:20:39.095+0000] {subprocess.py:93} INFO - 25/07/02 15:20:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ddb9a68c03a1:45547 (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:39.117+0000] {subprocess.py:93} INFO - 25/07/02 15:20:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:20:39.251+0000] {subprocess.py:93} INFO - 25/07/02 15:20:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:20:39.256+0000] {subprocess.py:93} INFO - 25/07/02 15:20:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-02T15:20:40.530+0000] {subprocess.py:93} INFO - 25/07/02 15:20:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 9819 bytes)
[2025-07-02T15:20:42.517+0000] {subprocess.py:93} INFO - 25/07/02 15:20:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.10:38649 (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:46.618+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 6196 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:20:46.628+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-02T15:20:46.658+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO DAGScheduler: ResultStage 0 (parquet at <unknown>:0) finished in 8.403 s
[2025-07-02T15:20:46.675+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:20:46.681+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-07-02T15:20:46.691+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO DAGScheduler: Job 0 finished: parquet at <unknown>:0, took 8.671096 s
[2025-07-02T15:20:46.955+0000] {subprocess.py:93} INFO - 25/07/02 15:20:46 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
[2025-07-02T15:20:47.483+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO SparkContext: Starting job: parquet at <unknown>:0
[2025-07-02T15:20:47.518+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Got job 1 (parquet at <unknown>:0) with 1 output partitions
[2025-07-02T15:20:47.519+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at <unknown>:0)
[2025-07-02T15:20:47.519+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:20:47.520+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:20:47.526+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at parquet at <unknown>:0), which has no missing parents
[2025-07-02T15:20:47.656+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 104.7 KiB, free 434.2 MiB)
[2025-07-02T15:20:47.814+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 434.1 MiB)
[2025-07-02T15:20:47.823+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ddb9a68c03a1:45547 (size: 37.8 KiB, free: 434.3 MiB)
[2025-07-02T15:20:47.875+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:20:47.929+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:20:47.931+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-07-02T15:20:47.966+0000] {subprocess.py:93} INFO - 25/07/02 15:20:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 9818 bytes)
[2025-07-02T15:20:49.458+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ddb9a68c03a1:45547 in memory (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:49.634+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.10:38649 in memory (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:49.636+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.10:38649 (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:49.850+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1894 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:20:49.852+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-02T15:20:49.858+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO DAGScheduler: ResultStage 1 (parquet at <unknown>:0) finished in 2.316 s
[2025-07-02T15:20:49.860+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:20:49.867+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-02T15:20:49.869+0000] {subprocess.py:93} INFO - 25/07/02 15:20:49 INFO DAGScheduler: Job 1 finished: parquet at <unknown>:0, took 2.386809 s
[2025-07-02T15:20:50.515+0000] {subprocess.py:93} INFO - --------------------almost here--------------------------------------
[2025-07-02T15:20:53.945+0000] {subprocess.py:93} INFO - 25/07/02 15:20:53 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-02T15:20:53.950+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-02T15:20:53.951+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9093]
[2025-07-02T15:20:53.951+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-02T15:20:53.951+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-02T15:20:53.951+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-02T15:20:53.952+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-02T15:20:53.952+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-02T15:20:53.952+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-02T15:20:53.953+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-02T15:20:53.954+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-02T15:20:53.955+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-02T15:20:53.955+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-02T15:20:53.956+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-02T15:20:53.957+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-02T15:20:53.957+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-02T15:20:53.958+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-02T15:20:53.958+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-02T15:20:53.958+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-02T15:20:53.959+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-02T15:20:53.959+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-02T15:20:53.960+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-02T15:20:53.960+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-02T15:20:53.960+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-02T15:20:53.960+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-02T15:20:53.961+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-02T15:20:53.962+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-02T15:20:53.962+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-02T15:20:53.962+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-02T15:20:53.962+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-02T15:20:53.963+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-02T15:20:53.963+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-02T15:20:53.963+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-02T15:20:53.963+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-02T15:20:53.964+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-02T15:20:53.964+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-02T15:20:53.964+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-02T15:20:53.964+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-02T15:20:53.965+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-02T15:20:53.965+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-02T15:20:53.966+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-02T15:20:53.966+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-02T15:20:53.966+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-02T15:20:53.966+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-02T15:20:53.967+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-02T15:20:53.968+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-02T15:20:53.968+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-02T15:20:53.968+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-02T15:20:53.968+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-02T15:20:53.968+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-02T15:20:53.969+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-02T15:20:53.969+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-02T15:20:53.969+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-02T15:20:53.970+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-02T15:20:53.970+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-02T15:20:53.970+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-02T15:20:53.971+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-02T15:20:53.972+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-02T15:20:53.972+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-02T15:20:53.973+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-02T15:20:53.974+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:20:54.183+0000] {subprocess.py:93} INFO - 25/07/02 15:20:54 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-02T15:20:54.219+0000] {subprocess.py:93} INFO - 25/07/02 15:20:54 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-02T15:20:54.221+0000] {subprocess.py:93} INFO - 25/07/02 15:20:54 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-02T15:20:54.223+0000] {subprocess.py:93} INFO - 25/07/02 15:20:54 INFO AppInfoParser: Kafka startTimeMs: 1751469654182
[2025-07-02T15:20:55.494+0000] {subprocess.py:93} INFO - 25/07/02 15:20:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ddb9a68c03a1:45547 in memory (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:55.596+0000] {subprocess.py:93} INFO - 25/07/02 15:20:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.10:38649 in memory (size: 37.8 KiB, free: 434.4 MiB)
[2025-07-02T15:20:56.956+0000] {subprocess.py:93} INFO - 25/07/02 15:20:56 INFO AppInfoParser: App info kafka.admin.client for adminclient-1 unregistered
[2025-07-02T15:20:56.971+0000] {subprocess.py:93} INFO - 25/07/02 15:20:56 INFO Metrics: Metrics scheduler closed
[2025-07-02T15:20:56.973+0000] {subprocess.py:93} INFO - 25/07/02 15:20:56 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-02T15:20:56.974+0000] {subprocess.py:93} INFO - 25/07/02 15:20:56 INFO Metrics: Metrics reporters closed
[2025-07-02T15:20:56.987+0000] {subprocess.py:93} INFO - 25/07/02 15:20:56 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(transaction-events-0,-2,-1,None)
[2025-07-02T15:20:58.101+0000] {subprocess.py:93} INFO - 25/07/02 15:20:58 INFO CodeGenerator: Code generated in 481.355458 ms
[2025-07-02T15:20:59.007+0000] {subprocess.py:93} INFO - 25/07/02 15:20:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(customer_id)
[2025-07-02T15:20:59.025+0000] {subprocess.py:93} INFO - 25/07/02 15:20:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(customer_id#28)
[2025-07-02T15:20:59.114+0000] {subprocess.py:93} INFO - 25/07/02 15:20:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
[2025-07-02T15:20:59.116+0000] {subprocess.py:93} INFO - 25/07/02 15:20:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#38)
[2025-07-02T15:21:01.824+0000] {subprocess.py:93} INFO - 25/07/02 15:21:01 INFO CodeGenerator: Code generated in 739.189042 ms
[2025-07-02T15:21:01.834+0000] {subprocess.py:93} INFO - 25/07/02 15:21:01 INFO CodeGenerator: Code generated in 738.995833 ms
[2025-07-02T15:21:02.154+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 203.0 KiB, free 434.2 MiB)
[2025-07-02T15:21:02.244+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 203.1 KiB, free 434.0 MiB)
[2025-07-02T15:21:02.286+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 434.0 MiB)
[2025-07-02T15:21:02.289+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ddb9a68c03a1:45547 (size: 35.6 KiB, free: 434.4 MiB)
[2025-07-02T15:21:02.302+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 433.9 MiB)
[2025-07-02T15:21:02.312+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ddb9a68c03a1:45547 (size: 35.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:02.313+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO SparkContext: Created broadcast 2 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:02.316+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:02.439+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-02T15:21:02.442+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-02T15:21:02.813+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:02.815+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:02.828+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:02.829+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-07-02T15:21:02.830+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:02.832+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:02.841+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-07-02T15:21:02.872+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 433.9 MiB)
[2025-07-02T15:21:02.900+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.9 MiB)
[2025-07-02T15:21:02.909+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ddb9a68c03a1:45547 (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:02.913+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:02.917+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:02.918+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-02T15:21:02.925+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:02.927+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-07-02T15:21:02.929+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:02.930+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:02.941+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-07-02T15:21:02.979+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.4 KiB, free 433.9 MiB)
[2025-07-02T15:21:02.981+0000] {subprocess.py:93} INFO - 25/07/02 15:21:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 10326 bytes)
[2025-07-02T15:21:03.128+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.9 MiB)
[2025-07-02T15:21:03.134+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ddb9a68c03a1:45547 (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:03.147+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:03.159+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:03.161+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-07-02T15:21:03.186+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 10325 bytes)
[2025-07-02T15:21:03.785+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.10:38649 (size: 6.8 KiB, free: 434.4 MiB)
[2025-07-02T15:21:03.793+0000] {subprocess.py:93} INFO - 25/07/02 15:21:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.10:38649 (size: 6.7 KiB, free: 434.4 MiB)
[2025-07-02T15:21:07.837+0000] {subprocess.py:93} INFO - 25/07/02 15:21:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.10:38649 (size: 35.7 KiB, free: 434.4 MiB)
[2025-07-02T15:21:07.852+0000] {subprocess.py:93} INFO - 25/07/02 15:21:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.10:38649 (size: 35.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:11.252+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 8025 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:11.267+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-02T15:21:11.268+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 8306 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:11.269+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-02T15:21:11.270+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 8.303 s
[2025-07-02T15:21:11.271+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:11.274+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-02T15:21:11.284+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 8.466748 s
[2025-07-02T15:21:11.287+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 8.427 s
[2025-07-02T15:21:11.289+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:11.290+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-07-02T15:21:11.293+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 8.481511 s
[2025-07-02T15:21:11.672+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO CodeGenerator: Code generated in 180.532667 ms
[2025-07-02T15:21:11.744+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 299.0 B, free 433.9 MiB)
[2025-07-02T15:21:11.745+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 268.0 B, free 433.9 MiB)
[2025-07-02T15:21:11.750+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ddb9a68c03a1:45547 (size: 299.0 B, free: 434.3 MiB)
[2025-07-02T15:21:11.752+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ddb9a68c03a1:45547 (size: 268.0 B, free: 434.3 MiB)
[2025-07-02T15:21:11.756+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:11.757+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:11.941+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-02T15:21:11.943+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-02T15:21:11.944+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9093]
[2025-07-02T15:21:11.945+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-02T15:21:11.946+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-02T15:21:11.947+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-02T15:21:11.949+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-02T15:21:11.950+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-02T15:21:11.951+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-02T15:21:11.953+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-02T15:21:11.956+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-02T15:21:11.958+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-02T15:21:11.959+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-02T15:21:11.964+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-02T15:21:11.968+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-02T15:21:11.972+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-02T15:21:11.977+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-02T15:21:11.978+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-02T15:21:11.980+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-02T15:21:11.980+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-02T15:21:11.982+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-02T15:21:11.988+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-02T15:21:11.990+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-02T15:21:11.996+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-02T15:21:11.999+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-02T15:21:12.000+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-02T15:21:12.001+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-02T15:21:12.002+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-02T15:21:12.003+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-02T15:21:12.007+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-02T15:21:12.009+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-02T15:21:12.010+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-02T15:21:12.011+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-02T15:21:12.013+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-02T15:21:12.014+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-02T15:21:12.016+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-02T15:21:12.017+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-02T15:21:12.018+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-02T15:21:12.023+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-02T15:21:12.026+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-02T15:21:12.028+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-02T15:21:12.029+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-02T15:21:12.031+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-02T15:21:12.042+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-02T15:21:12.049+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-02T15:21:12.054+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-02T15:21:12.059+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-02T15:21:12.062+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-02T15:21:12.064+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-02T15:21:12.067+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-02T15:21:12.067+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-02T15:21:12.071+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-02T15:21:12.075+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-02T15:21:12.081+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-02T15:21:12.088+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-02T15:21:12.090+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-02T15:21:12.092+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-02T15:21:12.095+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-02T15:21:12.105+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-02T15:21:12.106+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-02T15:21:12.108+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-02T15:21:12.109+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-02T15:21:12.109+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-02T15:21:12.110+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-02T15:21:12.110+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-02T15:21:12.111+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-02T15:21:12.111+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-02T15:21:12.112+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-02T15:21:12.113+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-02T15:21:12.113+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-02T15:21:12.114+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:21:12.117+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-02T15:21:12.118+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-02T15:21:12.119+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-02T15:21:12.119+0000] {subprocess.py:93} INFO - 25/07/02 15:21:11 INFO AppInfoParser: Kafka startTimeMs: 1751469671980
[2025-07-02T15:21:12.401+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AppInfoParser: App info kafka.admin.client for adminclient-2 unregistered
[2025-07-02T15:21:12.429+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO Metrics: Metrics scheduler closed
[2025-07-02T15:21:12.431+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-02T15:21:12.437+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO Metrics: Metrics reporters closed
[2025-07-02T15:21:12.438+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(transaction-events-0,-2,-1,None)
[2025-07-02T15:21:12.982+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-02T15:21:12.987+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-02T15:21:12.989+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9093]
[2025-07-02T15:21:12.990+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-02T15:21:12.991+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-02T15:21:12.991+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-02T15:21:12.992+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-02T15:21:12.993+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-02T15:21:12.995+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-02T15:21:12.996+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-02T15:21:12.998+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-02T15:21:12.999+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-02T15:21:12.999+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-02T15:21:13.000+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-02T15:21:13.000+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-02T15:21:13.001+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-02T15:21:13.002+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-02T15:21:13.002+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-02T15:21:13.002+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-02T15:21:13.003+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-02T15:21:13.008+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-02T15:21:13.009+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-02T15:21:13.010+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-02T15:21:13.011+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-02T15:21:13.012+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-02T15:21:13.013+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-02T15:21:13.014+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-02T15:21:13.016+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-02T15:21:13.017+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-02T15:21:13.018+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-02T15:21:13.019+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-02T15:21:13.020+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-02T15:21:13.021+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-02T15:21:13.022+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-02T15:21:13.023+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-02T15:21:13.024+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-02T15:21:13.025+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-02T15:21:13.026+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-02T15:21:13.028+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-02T15:21:13.029+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-02T15:21:13.030+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-02T15:21:13.031+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-02T15:21:13.031+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-02T15:21:13.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-02T15:21:13.032+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-02T15:21:13.033+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-02T15:21:13.037+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-02T15:21:13.040+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-02T15:21:13.042+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-02T15:21:13.043+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-02T15:21:13.044+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-02T15:21:13.047+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-02T15:21:13.050+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-02T15:21:13.053+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-02T15:21:13.054+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-02T15:21:13.055+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-02T15:21:13.055+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-02T15:21:13.056+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-02T15:21:13.057+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-02T15:21:13.058+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-02T15:21:13.058+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-02T15:21:13.059+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-02T15:21:13.059+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-02T15:21:13.060+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-02T15:21:13.061+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-02T15:21:13.061+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-02T15:21:13.062+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-02T15:21:13.063+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-02T15:21:13.063+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-02T15:21:13.064+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-02T15:21:13.065+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:21:13.066+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-02T15:21:13.068+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-02T15:21:13.070+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-02T15:21:13.071+0000] {subprocess.py:93} INFO - 25/07/02 15:21:12 INFO AppInfoParser: Kafka startTimeMs: 1751469672990
[2025-07-02T15:21:13.181+0000] {subprocess.py:93} INFO - 25/07/02 15:21:13 INFO AppInfoParser: App info kafka.admin.client for adminclient-3 unregistered
[2025-07-02T15:21:13.212+0000] {subprocess.py:93} INFO - 25/07/02 15:21:13 INFO Metrics: Metrics scheduler closed
[2025-07-02T15:21:13.214+0000] {subprocess.py:93} INFO - 25/07/02 15:21:13 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-02T15:21:13.216+0000] {subprocess.py:93} INFO - 25/07/02 15:21:13 INFO Metrics: Metrics reporters closed
[2025-07-02T15:21:13.219+0000] {subprocess.py:93} INFO - 25/07/02 15:21:13 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(transaction-events-0,-2,-1,None)
[2025-07-02T15:21:14.072+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO CodeGenerator: Code generated in 310.047792 ms
[2025-07-02T15:21:14.227+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO CodeGenerator: Code generated in 105.765 ms
[2025-07-02T15:21:14.409+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO SparkContext: Starting job: showString at <unknown>:0
[2025-07-02T15:21:14.425+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Got job 4 (showString at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:14.429+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Final stage: ResultStage 4 (showString at <unknown>:0)
[2025-07-02T15:21:14.438+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:14.440+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:14.444+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[36] at showString at <unknown>:0), which has no missing parents
[2025-07-02T15:21:14.728+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 56.3 KiB, free 433.8 MiB)
[2025-07-02T15:21:14.887+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 433.8 MiB)
[2025-07-02T15:21:14.889+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ddb9a68c03a1:45547 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:14.894+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ddb9a68c03a1:45547 (size: 21.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:14.909+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:14.920+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[36] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:14.922+0000] {subprocess.py:93} INFO - 25/07/02 15:21:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-02T15:21:15.016+0000] {subprocess.py:93} INFO - 25/07/02 15:21:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 9844 bytes)
[2025-07-02T15:21:15.259+0000] {subprocess.py:93} INFO - 25/07/02 15:21:15 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.10:38649 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:15.490+0000] {subprocess.py:93} INFO - 25/07/02 15:21:15 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ddb9a68c03a1:45547 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:15.550+0000] {subprocess.py:93} INFO - 25/07/02 15:21:15 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.10:38649 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:15.726+0000] {subprocess.py:93} INFO - 25/07/02 15:21:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.10:38649 (size: 21.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:26.979+0000] {subprocess.py:93} INFO - 25/07/02 15:21:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.10:38649 (size: 299.0 B, free: 434.3 MiB)
[2025-07-02T15:21:27.173+0000] {subprocess.py:93} INFO - 25/07/02 15:21:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.10:38649 (size: 268.0 B, free: 434.3 MiB)
[2025-07-02T15:21:31.959+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 16964 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:31.972+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-02T15:21:31.973+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO DAGScheduler: ResultStage 4 (showString at <unknown>:0) finished in 17.471 s
[2025-07-02T15:21:31.973+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:31.974+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-07-02T15:21:31.975+0000] {subprocess.py:93} INFO - 25/07/02 15:21:31 INFO DAGScheduler: Job 4 finished: showString at <unknown>:0, took 17.565237 s
[2025-07-02T15:21:38.144+0000] {subprocess.py:93} INFO - 25/07/02 15:21:38 INFO CodeGenerator: Code generated in 210.991459 ms
[2025-07-02T15:21:38.258+0000] {subprocess.py:93} INFO - +----------+-----------+-------+--------+--------------------------+----------+---------+----------------+-----------+------------+-----------+-----+
[2025-07-02T15:21:38.262+0000] {subprocess.py:93} INFO - |product_id|customer_id|sale_id|quantity|sale_timestamp            |first_name|last_name|email           |signup_date|product_name|category   |price|
[2025-07-02T15:21:38.265+0000] {subprocess.py:93} INFO - +----------+-----------+-------+--------+--------------------------+----------+---------+----------------+-----------+------------+-----------+-----+
[2025-07-02T15:21:38.268+0000] {subprocess.py:93} INFO - |102       |2          |459349 |5       |2025-07-02 15:04:35.542715|Jane      |Smith    |jane@example.com|2023-02-20 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.269+0000] {subprocess.py:93} INFO - |102       |1          |753966 |4       |2025-07-02 15:04:36.564243|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.271+0000] {subprocess.py:93} INFO - |102       |1          |670645 |2       |2025-07-02 15:04:37.572615|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.279+0000] {subprocess.py:93} INFO - |102       |1          |385734 |5       |2025-07-02 15:04:38.581473|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.281+0000] {subprocess.py:93} INFO - |102       |2          |103247 |2       |2025-07-02 15:04:39.593414|Jane      |Smith    |jane@example.com|2023-02-20 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.283+0000] {subprocess.py:93} INFO - |101       |2          |545894 |1       |2025-07-02 15:04:40.607515|Jane      |Smith    |jane@example.com|2023-02-20 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.286+0000] {subprocess.py:93} INFO - |102       |2          |733037 |3       |2025-07-02 15:04:41.613731|Jane      |Smith    |jane@example.com|2023-02-20 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.290+0000] {subprocess.py:93} INFO - |102       |2          |113088 |1       |2025-07-02 15:04:42.617727|Jane      |Smith    |jane@example.com|2023-02-20 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.293+0000] {subprocess.py:93} INFO - |101       |2          |221241 |3       |2025-07-02 15:04:43.628259|Jane      |Smith    |jane@example.com|2023-02-20 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.293+0000] {subprocess.py:93} INFO - |102       |1          |181144 |2       |2025-07-02 15:04:44.64763 |John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.295+0000] {subprocess.py:93} INFO - |101       |1          |745348 |1       |2025-07-02 15:04:45.663991|John      |Doe      |john@example.com|2023-01-10 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.296+0000] {subprocess.py:93} INFO - |102       |1          |266150 |3       |2025-07-02 15:04:46.669977|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.300+0000] {subprocess.py:93} INFO - |102       |2          |545638 |1       |2025-07-02 15:04:47.67814 |Jane      |Smith    |jane@example.com|2023-02-20 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.303+0000] {subprocess.py:93} INFO - |101       |2          |451114 |3       |2025-07-02 15:04:48.688484|Jane      |Smith    |jane@example.com|2023-02-20 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.304+0000] {subprocess.py:93} INFO - |101       |2          |723598 |4       |2025-07-02 15:04:49.694048|Jane      |Smith    |jane@example.com|2023-02-20 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.306+0000] {subprocess.py:93} INFO - |101       |1          |407967 |1       |2025-07-02 15:04:50.707439|John      |Doe      |john@example.com|2023-01-10 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.307+0000] {subprocess.py:93} INFO - |102       |1          |671069 |4       |2025-07-02 15:04:51.712361|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.311+0000] {subprocess.py:93} INFO - |102       |1          |426792 |3       |2025-07-02 15:04:52.71986 |John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.313+0000] {subprocess.py:93} INFO - |101       |2          |342540 |3       |2025-07-02 15:04:53.731521|Jane      |Smith    |jane@example.com|2023-02-20 |Phone       |Electronics|699  |
[2025-07-02T15:21:38.317+0000] {subprocess.py:93} INFO - |102       |1          |670722 |3       |2025-07-02 15:04:54.739531|John      |Doe      |john@example.com|2023-01-10 |Laptop      |Electronics|999  |
[2025-07-02T15:21:38.320+0000] {subprocess.py:93} INFO - +----------+-----------+-------+--------+--------------------------+----------+---------+----------------+-----------+------------+-----------+-----+
[2025-07-02T15:21:38.321+0000] {subprocess.py:93} INFO - only showing top 20 rows
[2025-07-02T15:21:38.322+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:21:39.171+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-02T15:21:39.178+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-02T15:21:39.178+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9093]
[2025-07-02T15:21:39.179+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-02T15:21:39.179+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-02T15:21:39.179+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-02T15:21:39.180+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-02T15:21:39.180+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-02T15:21:39.180+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-02T15:21:39.181+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-02T15:21:39.182+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-02T15:21:39.182+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-02T15:21:39.183+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-02T15:21:39.183+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-02T15:21:39.183+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-02T15:21:39.183+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-02T15:21:39.183+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-02T15:21:39.184+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-02T15:21:39.184+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-02T15:21:39.185+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-02T15:21:39.185+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-02T15:21:39.186+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-02T15:21:39.186+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-02T15:21:39.186+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-02T15:21:39.186+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-02T15:21:39.186+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-02T15:21:39.187+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-02T15:21:39.187+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-02T15:21:39.188+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-02T15:21:39.188+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-02T15:21:39.188+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-02T15:21:39.189+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-02T15:21:39.189+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-02T15:21:39.190+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-02T15:21:39.190+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-02T15:21:39.191+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-02T15:21:39.191+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-02T15:21:39.192+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-02T15:21:39.192+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-02T15:21:39.192+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-02T15:21:39.192+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-02T15:21:39.192+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-02T15:21:39.193+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-02T15:21:39.193+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-02T15:21:39.194+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-02T15:21:39.195+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-02T15:21:39.195+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-02T15:21:39.196+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-02T15:21:39.196+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-02T15:21:39.197+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-02T15:21:39.197+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-02T15:21:39.197+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-02T15:21:39.197+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-02T15:21:39.198+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-02T15:21:39.199+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-02T15:21:39.199+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-02T15:21:39.199+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-02T15:21:39.199+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-02T15:21:39.200+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-02T15:21:39.200+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-02T15:21:39.215+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-02T15:21:39.215+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-02T15:21:39.216+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-02T15:21:39.216+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-02T15:21:39.216+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-02T15:21:39.216+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:21:39.359+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-02T15:21:39.360+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-02T15:21:39.361+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-02T15:21:39.362+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AppInfoParser: Kafka startTimeMs: 1751469699356
[2025-07-02T15:21:39.684+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO AppInfoParser: App info kafka.admin.client for adminclient-4 unregistered
[2025-07-02T15:21:39.692+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO Metrics: Metrics scheduler closed
[2025-07-02T15:21:39.694+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-02T15:21:39.697+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO Metrics: Metrics reporters closed
[2025-07-02T15:21:39.698+0000] {subprocess.py:93} INFO - 25/07/02 15:21:39 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(transaction-events-0,-2,-1,None)
[2025-07-02T15:21:40.038+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceStrategy: Pushed Filters: IsNotNull(customer_id)
[2025-07-02T15:21:40.043+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(customer_id#28)
[2025-07-02T15:21:40.053+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceStrategy: Pushed Filters: IsNotNull(product_id)
[2025-07-02T15:21:40.057+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(product_id#38)
[2025-07-02T15:21:40.451+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 203.0 KiB, free 433.5 MiB)
[2025-07-02T15:21:40.462+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 203.1 KiB, free 433.5 MiB)
[2025-07-02T15:21:40.544+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 433.4 MiB)
[2025-07-02T15:21:40.545+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 433.4 MiB)
[2025-07-02T15:21:40.552+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ddb9a68c03a1:45547 (size: 35.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:40.555+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ddb9a68c03a1:45547 (size: 35.7 KiB, free: 434.2 MiB)
[2025-07-02T15:21:40.581+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:40.582+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:40.610+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-02T15:21:40.611+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-02T15:21:40.707+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:40.709+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:40.724+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:40.725+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-07-02T15:21:40.726+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:40.729+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:40.735+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-07-02T15:21:40.765+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 17.0 KiB, free 433.4 MiB)
[2025-07-02T15:21:41.016+0000] {subprocess.py:93} INFO - 25/07/02 15:21:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.4 MiB)
[2025-07-02T15:21:41.038+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ddb9a68c03a1:45547 in memory (size: 35.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.058+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on ddb9a68c03a1:45547 (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.075+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:41.092+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:41.095+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-07-02T15:21:41.130+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:41.133+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-07-02T15:21:41.137+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:41.141+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:41.150+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-07-02T15:21:41.161+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 10326 bytes)
[2025-07-02T15:21:41.243+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.4 KiB, free 433.6 MiB)
[2025-07-02T15:21:41.269+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.6 MiB)
[2025-07-02T15:21:41.274+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.10:38649 in memory (size: 35.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.280+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on ddb9a68c03a1:45547 (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.290+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:41.295+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:41.297+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-07-02T15:21:41.322+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 10325 bytes)
[2025-07-02T15:21:41.422+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ddb9a68c03a1:45547 in memory (size: 35.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.491+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.10:38649 in memory (size: 35.7 KiB, free: 434.4 MiB)
[2025-07-02T15:21:41.544+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ddb9a68c03a1:45547 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:41.569+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.10:38649 in memory (size: 21.6 KiB, free: 434.4 MiB)
[2025-07-02T15:21:41.650+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ddb9a68c03a1:45547 in memory (size: 268.0 B, free: 434.3 MiB)
[2025-07-02T15:21:41.651+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.10:38649 (size: 6.8 KiB, free: 434.4 MiB)
[2025-07-02T15:21:41.656+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.10:38649 (size: 6.7 KiB, free: 434.4 MiB)
[2025-07-02T15:21:41.674+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.10:38649 in memory (size: 268.0 B, free: 434.4 MiB)
[2025-07-02T15:21:41.699+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ddb9a68c03a1:45547 in memory (size: 299.0 B, free: 434.3 MiB)
[2025-07-02T15:21:41.740+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.10:38649 in memory (size: 299.0 B, free: 434.4 MiB)
[2025-07-02T15:21:41.793+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.10:38649 (size: 35.7 KiB, free: 434.4 MiB)
[2025-07-02T15:21:41.797+0000] {subprocess.py:93} INFO - 25/07/02 15:21:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.10:38649 (size: 35.6 KiB, free: 434.3 MiB)
[2025-07-02T15:21:42.233+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1079 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:42.234+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-02T15:21:42.235+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 923 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:42.236+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-07-02T15:21:42.236+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 1.492 s
[2025-07-02T15:21:42.243+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:42.246+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-02T15:21:42.250+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 1.542509 s
[2025-07-02T15:21:42.260+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 1.094 s
[2025-07-02T15:21:42.261+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:42.262+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-07-02T15:21:42.263+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 1.556157 s
[2025-07-02T15:21:42.457+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 268.0 B, free 433.9 MiB)
[2025-07-02T15:21:42.460+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 299.0 B, free 433.9 MiB)
[2025-07-02T15:21:42.465+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on ddb9a68c03a1:45547 (size: 299.0 B, free: 434.3 MiB)
[2025-07-02T15:21:42.470+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on ddb9a68c03a1:45547 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:42.471+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on ddb9a68c03a1:45547 (size: 268.0 B, free: 434.3 MiB)
[2025-07-02T15:21:42.503+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:42.511+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-07-02T15:21:42.701+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.10:38649 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-07-02T15:21:42.778+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-02T15:21:42.781+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-02T15:21:42.786+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9093]
[2025-07-02T15:21:42.787+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-02T15:21:42.787+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-02T15:21:42.791+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-02T15:21:42.792+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-02T15:21:42.792+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-02T15:21:42.793+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-02T15:21:42.794+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-02T15:21:42.795+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-02T15:21:42.796+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-02T15:21:42.798+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-02T15:21:42.803+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-02T15:21:42.804+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-02T15:21:42.806+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-02T15:21:42.807+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-02T15:21:42.808+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-02T15:21:42.809+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-02T15:21:42.810+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-02T15:21:42.811+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-02T15:21:42.812+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-02T15:21:42.814+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-02T15:21:42.815+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-02T15:21:42.816+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-02T15:21:42.817+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-02T15:21:42.817+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-02T15:21:42.818+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-02T15:21:42.819+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-02T15:21:42.820+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-02T15:21:42.820+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-02T15:21:42.822+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-02T15:21:42.824+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-02T15:21:42.827+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-02T15:21:42.828+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-02T15:21:42.831+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-02T15:21:42.833+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-02T15:21:42.833+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-02T15:21:42.833+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-02T15:21:42.834+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-02T15:21:42.835+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-02T15:21:42.836+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-02T15:21:42.836+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-02T15:21:42.837+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-02T15:21:42.838+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-02T15:21:42.838+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-02T15:21:42.840+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-02T15:21:42.844+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-02T15:21:42.844+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-02T15:21:42.847+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-02T15:21:42.850+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-02T15:21:42.852+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-02T15:21:42.854+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-02T15:21:42.856+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-02T15:21:42.859+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-02T15:21:42.860+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-02T15:21:42.860+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-02T15:21:42.863+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-02T15:21:42.864+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-02T15:21:42.867+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-02T15:21:42.868+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-02T15:21:42.868+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-02T15:21:42.869+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-02T15:21:42.870+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-02T15:21:42.871+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-02T15:21:42.871+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-02T15:21:42.872+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-02T15:21:42.873+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-02T15:21:42.874+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-02T15:21:42.875+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-02T15:21:42.877+0000] {subprocess.py:93} INFO - 
[2025-07-02T15:21:42.878+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on ddb9a68c03a1:45547 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:42.879+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.10:38649 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-07-02T15:21:42.879+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-02T15:21:42.880+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-02T15:21:42.882+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-02T15:21:42.882+0000] {subprocess.py:93} INFO - 25/07/02 15:21:42 INFO AppInfoParser: Kafka startTimeMs: 1751469702847
[2025-07-02T15:21:43.075+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO AppInfoParser: App info kafka.admin.client for adminclient-5 unregistered
[2025-07-02T15:21:43.085+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO Metrics: Metrics scheduler closed
[2025-07-02T15:21:43.087+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-02T15:21:43.087+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO Metrics: Metrics reporters closed
[2025-07-02T15:21:43.090+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(transaction-events-0,-2,-1,None)
[2025-07-02T15:21:43.679+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-02T15:21:43.682+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-02T15:21:43.684+0000] {subprocess.py:93} INFO - 25/07/02 15:21:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2025-07-02T15:21:44.615+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO CodeGenerator: Code generated in 355.88725 ms
[2025-07-02T15:21:44.908+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO SparkContext: Starting job: csv at <unknown>:0
[2025-07-02T15:21:44.916+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO DAGScheduler: Got job 7 (csv at <unknown>:0) with 1 output partitions
[2025-07-02T15:21:44.917+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO DAGScheduler: Final stage: ResultStage 7 (csv at <unknown>:0)
[2025-07-02T15:21:44.927+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO DAGScheduler: Parents of final stage: List()
[2025-07-02T15:21:44.928+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO DAGScheduler: Missing parents: List()
[2025-07-02T15:21:44.932+0000] {subprocess.py:93} INFO - 25/07/02 15:21:44 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[62] at csv at <unknown>:0), which has no missing parents
[2025-07-02T15:21:45.521+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 258.9 KiB, free 433.7 MiB)
[2025-07-02T15:21:45.845+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 93.3 KiB, free 433.6 MiB)
[2025-07-02T15:21:45.853+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on ddb9a68c03a1:45547 (size: 93.3 KiB, free: 434.2 MiB)
[2025-07-02T15:21:45.873+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2025-07-02T15:21:45.890+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[62] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-02T15:21:45.895+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-07-02T15:21:45.953+0000] {subprocess.py:93} INFO - 25/07/02 15:21:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (172.18.0.10, executor 0, partition 0, PROCESS_LOCAL, 9844 bytes)
[2025-07-02T15:21:46.325+0000] {subprocess.py:93} INFO - 25/07/02 15:21:46 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.10:38649 (size: 93.3 KiB, free: 434.2 MiB)
[2025-07-02T15:21:47.935+0000] {subprocess.py:93} INFO - 25/07/02 15:21:47 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.10:38649 (size: 299.0 B, free: 434.2 MiB)
[2025-07-02T15:21:48.350+0000] {subprocess.py:93} INFO - 25/07/02 15:21:48 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.10:38649 (size: 268.0 B, free: 434.2 MiB)
[2025-07-02T15:21:51.122+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5164 ms on 172.18.0.10 (executor 0) (1/1)
[2025-07-02T15:21:51.134+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-02T15:21:51.136+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO DAGScheduler: ResultStage 7 (csv at <unknown>:0) finished in 6.247 s
[2025-07-02T15:21:51.138+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-02T15:21:51.138+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-02T15:21:51.150+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO DAGScheduler: Job 7 finished: csv at <unknown>:0, took 6.305571 s
[2025-07-02T15:21:51.190+0000] {subprocess.py:93} INFO - 25/07/02 15:21:51 INFO FileFormatWriter: Start to commit write Job 28fcec64-90ae-4f50-86db-504e9f2a22ed.
[2025-07-02T15:21:52.232+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO FileFormatWriter: Write Job 28fcec64-90ae-4f50-86db-504e9f2a22ed committed. Elapsed time: 988 ms.
[2025-07-02T15:21:52.289+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO FileFormatWriter: Finished processing stats for write job 28fcec64-90ae-4f50-86db-504e9f2a22ed.
[2025-07-02T15:21:52.446+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-02T15:21:52.655+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO SparkUI: Stopped Spark web UI at http://ddb9a68c03a1:4040
[2025-07-02T15:21:52.698+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-07-02T15:21:52.702+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2025-07-02T15:21:52.915+0000] {subprocess.py:93} INFO - 25/07/02 15:21:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-02T15:21:53.489+0000] {subprocess.py:93} INFO - 25/07/02 15:21:53 INFO MemoryStore: MemoryStore cleared
[2025-07-02T15:21:53.504+0000] {subprocess.py:93} INFO - 25/07/02 15:21:53 INFO BlockManager: BlockManager stopped
[2025-07-02T15:21:53.549+0000] {subprocess.py:93} INFO - 25/07/02 15:21:53 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-02T15:21:53.604+0000] {subprocess.py:93} INFO - 25/07/02 15:21:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-02T15:21:54.087+0000] {subprocess.py:93} INFO - 25/07/02 15:21:54 INFO SparkContext: Successfully stopped SparkContext
[2025-07-02T15:21:55.815+0000] {subprocess.py:93} INFO - 25/07/02 15:21:55 INFO ShutdownHookManager: Shutdown hook called
[2025-07-02T15:21:55.825+0000] {subprocess.py:93} INFO - 25/07/02 15:21:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-66560e01-4344-4984-89db-c7124ff93ed5
[2025-07-02T15:21:55.960+0000] {subprocess.py:93} INFO - 25/07/02 15:21:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-7f0f9c52-ee24-4995-9425-47294ed42c70/pyspark-1590545a-dd2c-415c-a3f8-d5ca5c379c5b
[2025-07-02T15:21:56.031+0000] {subprocess.py:93} INFO - 25/07/02 15:21:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-7f0f9c52-ee24-4995-9425-47294ed42c70
[2025-07-02T15:21:56.467+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-02T15:21:56.943+0000] {taskinstance.py:1327} INFO - Marking task as SUCCESS. dag_id=retail_sales_pipeline, task_id=run_spark_job, execution_date=20250702T151439, start_date=20250702T151950, end_date=20250702T152156
[2025-07-02T15:21:57.088+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-02T15:21:57.405+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
